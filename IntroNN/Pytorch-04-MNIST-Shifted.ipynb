{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP on MNIST + Position Shift\n",
    "\n",
    "You can open this notebook either within a supported container or Google colaboratory [here](https://colab.research.google.com/github/slaclab/slacml-school/blob/master/IntroNN/Pytorch-04-MNIST-Shifted.ipynb).\n",
    "\n",
    "This notebook is similar to the previous notebooks where we applied MLP/CNN on MNIST dataset. What's new is that we look into how MLP performs when the digit's position is shifted (in both vertical and horizontal direction).\n",
    "\n",
    "## Goal\n",
    "1. Prepare MNIST dataset with position shift.\n",
    "2. Train MLP and CNN on MNIST digit images without a shift. \n",
    "3. Run the inference on the test dataset with translational shift. \n",
    "4. Try two more combinations of (train,test) = (shifted,shifted) and (shifted,no shift)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.figsize'] = [8, 6]\n",
    "mpl.rcParams['font.size'] = 16\n",
    "mpl.rcParams['axes.grid'] = True\n",
    "\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.device(device)\n",
    "import numpy as np\n",
    "SEED=12345\n",
    "_=np.random.seed(SEED)\n",
    "_=torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: `utils.py` module\n",
    "For this notebook, `utils.py` is prepared with handy functions. We will go over those functions briefly (+in details if requested!) but they are helpers and do not concern the core contents of programming ML components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare dataset\n",
    "\n",
    "Let's load MNIST dataset. You might have noticed that the MNIST dataset constructor can take a `transform` argument, which can be a composite of functions to be run upon preparing a dataset. This is handy: we already used a function to convert, automatically, image data into Pytorch tensor using `transforms.ToTensor()`. This time we also add what's called `utils.ImagePadder` that pads the MNIST 28x28 pixels images +N pixels in all ways (so it's (28+N)x(28+N) pixels). The constructor of `utils.ImagePadder` takes a boolean flag called `randomize` which then shifts the location of a digit within the padded image space.\n",
    "\n",
    "We prepare dataset and dataloader for both train and test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from utils import ImagePadder\n",
    "# Data file download directory\n",
    "LOCAL_DATA_DIR = './mnist-data'\n",
    "# Prepare train data\n",
    "train_dataset = datasets.MNIST(LOCAL_DATA_DIR, train=True, download=True,\n",
    "                               transform=transforms.Compose([ImagePadder(randomize=False),transforms.ToTensor()]))\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=32,shuffle=True,num_workers=2,pin_memory=True)\n",
    "# Prepare test data\n",
    "test_dataset = datasets.MNIST(LOCAL_DATA_DIR, train=False, download=True,\n",
    "                              transform=transforms.Compose([ImagePadder(randomize=True),transforms.ToTensor()]))\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,batch_size=32,shuffle=False,num_workers=2,pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Play with the dataset and figure out how many pixels we have padded (i.e. what's the image size?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing data\n",
    "\n",
    "I prepared another function that can visualize a list of classes and image. Let's visualize both train and test dataset. You should not see a shift for the train dataset, but the test dataset should show shifted locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize classes\n",
    "from utils import plot_dataset\n",
    "print('Train dataset')\n",
    "plot_dataset(train_dataset)\n",
    "print('Test dataset')\n",
    "plot_dataset(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"network\"></a>\n",
    "## 2. Train MLP and CNN on MNIST with no shift\n",
    "\n",
    "Let's define MLP and MNIST and train!\n",
    "\n",
    "### Exercise 2\n",
    "Design MLP and CNN the same way we did in the last notebook. Yes, that means you can _pretty much_ copy and paste, or you can practice trying to write from scratch :) I add a few required specifications below.\n",
    "\n",
    "* The model's constructor should take 2 optional arguments with default values: `image_size=48` and `num_filters=`16`.\n",
    "* MLP should have 2 `torch.nn.Linear` layers with `torch.nn.LeakyReLU` in between.\n",
    "* CNN should have 3 `torch.nn.Conv2d` layers followed by `torch.nn.LeakyReLU` and `torch.nn.MaxPool2d`\n",
    "  * Use the kernel size of 3 and stride 1 for the convolution layers\n",
    "  * Use the kernel size of 2 and stride 2 for pooling layers\n",
    "  * The number of filters in the first convolution layer should be `num_filters`, then it should increase by a factor of 2 each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's define a training and testing loop. We re-use the code we wrote in the previous hands-on session. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "\n",
    "def run_train(model, loader,  \n",
    "              num_iterations=100, log_dir='log',\n",
    "              lr=0.001, optimizer='SGD', device=None):\n",
    "    print(\"\\nTraining...\")\n",
    "    tstart = time.time()\n",
    "    if log_dir:\n",
    "        writer = SummaryWriter(log_dir=log_dir)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = getattr(torch.optim,optimizer)(model.parameters(),lr=lr)\n",
    "    f = IntProgress(min=0,max=int(num_iterations/100),bar_style='info')\n",
    "    display(f)\n",
    "    \n",
    "    iteration = 0\n",
    "    while iteration < num_iterations:\n",
    "        for data,label in loader:\n",
    "            \n",
    "            if device:\n",
    "                data,label = data.to(device),label.to(device)\n",
    "\n",
    "            loss = criterion(model(data), label)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if log_dir: \n",
    "                writer.add_scalar('loss/train', loss.item(), iteration)\n",
    "            if iteration%100 == 0:\n",
    "                f.value += 1\n",
    "            # Brake if we consumed all iteration counts\n",
    "            iteration += 1\n",
    "            if iteration >= num_iterations:\n",
    "                break\n",
    "    print('done',time.time()-tstart,'[s]')\n",
    "\n",
    "\n",
    "def run_test(model,loader,device=None):\n",
    "\n",
    "    label_v, softmax_v = [],[]\n",
    "    softmax = torch.nn.Softmax(dim=1)\n",
    "    f = IntProgress(min=0,max=int(len(loader)),bar_style='info')\n",
    "    display(f)\n",
    "    \n",
    "    with torch.set_grad_enabled(False):\n",
    "        for data,label in loader:\n",
    "            if device:\n",
    "                data,label = data.to(device), label.to(device)\n",
    "            label_v.append  ( label.detach().reshape(-1)   )\n",
    "            softmax_v.append( softmax(model(data)).detach())\n",
    "            f.value += 1\n",
    "    return torch.concat(label_v).cpu().numpy(), torch.concat(softmax_v).cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "* Train MLP and CNN\n",
    "* Compare the loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "%tensorboard --logdir tmnist_cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run the inference using the test dataset with a position shift\n",
    "\n",
    "Let's run the inference and print out the accuracy on the total test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# MLP\n",
    "label, softmax = run_test(mlp,test_loader,device=device)\n",
    "\n",
    "print('MLP accuracy',(np.argmax(softmax,axis=1) == label).sum() / len(label))\n",
    "\n",
    "result_mlp = dict(label=label, softmax=softmax)\n",
    "\n",
    "# CNN\n",
    "label, softmax = run_test(cnn,test_loader,device=device)\n",
    "\n",
    "print('CNN accuracy',(np.argmax(softmax,axis=1) == label).sum() / len(label))\n",
    "\n",
    "result_cnn = dict(label=label, softmax=softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Viola_! You can see CNN seems to work well, not too far from how it worked on 28x28 original MNIST images without a shift. On the other hand, MLP performs very poorly, only slightly better than a completely random guess (which would have been 0.1). Hopefully this demonstrated the feature of CNN which can learn translation invariant features.\n",
    "\n",
    "### Correlation among classification target types\n",
    "Without going details in how, I prepared 2 functions:\n",
    "\n",
    "* `plot_softmax` shows the correlation of softmax score across different digits for each image. You see a decagon with digit types on each edge with lots of dots inside. Each dot represent the softmax score of one image. The location of a dot is determined by interpreting the softmax score as a position vector from the origin. If the score is completley uncertain (i.e. 0.1 for each type), this would put a point in the middle. If it is 100% a certain digit type, the dot will be on the correponding edge of the decagon.\n",
    "\n",
    "* `plot_confusion_matrix` creates a classification output matrix that shows the true label type v.s. predicted type with the number of images filling the matrix cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_softmax\n",
    "\n",
    "plot_softmax(result_mlp['label'], result_mlp['softmax'], np.arange(10))\n",
    "\n",
    "plot_softmax(result_cnn['label'], result_cnn['softmax'], np.arange(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(np.argmax(result_mlp['softmax'],axis=1),result_mlp['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_confusion_matrix\n",
    "\n",
    "plot_confusion_matrix(result_mlp['label'],\n",
    "                      np.argmax(result_mlp['softmax'],axis=1),\n",
    "                      np.arange(10))\n",
    "\n",
    "plot_confusion_matrix(result_cnn['label'],\n",
    "                      np.argmax(result_cnn['softmax'],axis=1),\n",
    "                      np.arange(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: repeat the study using (train,test) = (shifted,shifted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: repeat the study using (train,test) = (shifted,no shift)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
